{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c4bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.0001)\n",
      "tensor(9.9531, dtype=torch.float16)\n",
      "tensor(10.0021)\n",
      "tensor(10.0021)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def test_mixed_precision():\n",
    "    s = torch.tensor(0, dtype=torch.float32)\n",
    "    for i in range(1000):\n",
    "        s += torch.tensor(0.01, dtype=torch.float32)\n",
    "    print(s)\n",
    "\n",
    "    s = torch.tensor(0, dtype=torch.float16)\n",
    "    for i in range(1000):\n",
    "        s += torch.tensor(0.01, dtype=torch.float16)\n",
    "    print(s)\n",
    "\n",
    "    s = torch.tensor(0, dtype=torch.float32)\n",
    "    for i in range(1000):\n",
    "        s += torch.tensor(0.01, dtype=torch.float16)\n",
    "    print(s)\n",
    "\n",
    "    s = torch.tensor(0, dtype=torch.float32)\n",
    "    for i in range(1000):\n",
    "        x = torch.tensor(0.01, dtype=torch.float16)\n",
    "        s += x.type(torch.float32)\n",
    "    print(s)\n",
    "test_mixed_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098cdf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.]])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import einops\n",
    "def weighted_sum(x: torch.Tensor, weight: torch.Tensor):\n",
    "    # Here, assume that x has n-dim shape [..., D], and weight has 1D shape [D]\n",
    "    return einops.einsum(x, weight, \"... D, D -> ...\").sum(dim=-1)\n",
    "\n",
    "x = torch.ones((1, 5))\n",
    "print(x)\n",
    "w = torch.ones((5,))\n",
    "print(w)\n",
    "weighted_sum(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37704f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1511/3604355764.py:9: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  a = torch.range(1, 5).view(5, 1)\n",
      "/tmp/ipykernel_1511/3604355764.py:10: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  b = torch.range(1, 5).view(1, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  3.,  4.,  5.,  6.],\n",
       "        [ 3.,  4.,  5.,  6.,  7.],\n",
       "        [ 4.,  5.,  6.,  7.,  8.],\n",
       "        [ 5.,  6.,  7.,  8.,  9.],\n",
       "        [ 6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "# a = torch.range(1, 5).view(5, 1)\n",
    "# b = torch.ones(5, 2)\n",
    "# (5, 1) * (5, 2)\n",
    "# a * b\n",
    "# (2, 5) * (5, 1)\n",
    "# b.transpose(1, 0) @ a\n",
    "\n",
    "a = torch.range(1, 5).view(5, 1)\n",
    "b = torch.range(1, 5).view(1, 5)\n",
    "\n",
    "a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251a06df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 20, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((1, 5, 20))\n",
    "print(x)\n",
    "x.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33de691a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/code/assignment2-systems/profile_results/out.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m json_file_path = \u001b[33m'\u001b[39m\u001b[33m/home/ubuntu/code/assignment2-systems/profile_results/out.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m json_array = json.load(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      5\u001b[39m df = pd.DataFrame(json_array)\n\u001b[32m      6\u001b[39m pd.concat([pd.json_normalize(df[\u001b[33m\"\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m\"\u001b[39m]), df[\u001b[33m\"\u001b[39m\u001b[33mtest_mean_time\u001b[39m\u001b[33m\"\u001b[39m]], axis = \u001b[32m1\u001b[39m) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my_code/cs336/assignment2-systems/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/ubuntu/code/assignment2-systems/profile_results/out.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872e23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>device</th>\n",
       "      <th>context_length</th>\n",
       "      <th>d_model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>torch_compile</th>\n",
       "      <th>test_mean_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>8.615449e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.785491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>3.693909e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.726874e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.589174e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.848333e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>4.420176e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.867052e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.494084e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>3.834974e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>4.616002e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.042146e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.699007e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>5.401137e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>6.715345e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.977401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name device  context_length  d_model  batch_size  torch_compile  \\\n",
       "0   AttentionLayer   cuda             256       16           8           True   \n",
       "1   AttentionLayer   cuda            1024       16           8           True   \n",
       "2   AttentionLayer   cuda            4096       16           8           True   \n",
       "3   AttentionLayer   cuda            8192       16           8           True   \n",
       "4   AttentionLayer   cuda           16384       16           8           True   \n",
       "5   AttentionLayer   cuda             256       32           8           True   \n",
       "6   AttentionLayer   cuda            1024       32           8           True   \n",
       "7   AttentionLayer   cuda            4096       32           8           True   \n",
       "8   AttentionLayer   cuda            8192       32           8           True   \n",
       "9   AttentionLayer   cuda           16384       32           8           True   \n",
       "10  AttentionLayer   cuda             256       64           8           True   \n",
       "11  AttentionLayer   cuda            1024       64           8           True   \n",
       "12  AttentionLayer   cuda            4096       64           8           True   \n",
       "13  AttentionLayer   cuda            8192       64           8           True   \n",
       "14  AttentionLayer   cuda           16384       64           8           True   \n",
       "15  AttentionLayer   cuda             256      128           8           True   \n",
       "16  AttentionLayer   cuda            1024      128           8           True   \n",
       "17  AttentionLayer   cuda            4096      128           8           True   \n",
       "18  AttentionLayer   cuda            8192      128           8           True   \n",
       "19  AttentionLayer   cuda           16384      128           8           True   \n",
       "\n",
       "    test_mean_time  \n",
       "0     8.615449e-04  \n",
       "1     2.785491e-03  \n",
       "2     3.693909e-02  \n",
       "3     1.726874e-01  \n",
       "4     1.000000e+10  \n",
       "5     9.589174e-04  \n",
       "6     2.848333e-03  \n",
       "7     4.420176e-02  \n",
       "8     1.867052e-01  \n",
       "9     1.000000e+10  \n",
       "10    9.494084e-04  \n",
       "11    3.834974e-03  \n",
       "12    4.616002e-02  \n",
       "13    2.042146e-01  \n",
       "14    1.000000e+10  \n",
       "15    9.699007e-04  \n",
       "16    5.401137e-03  \n",
       "17    6.715345e-02  \n",
       "18    2.977401e-01  \n",
       "19    1.000000e+10  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out_compile.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcae602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>device</th>\n",
       "      <th>torch_compile</th>\n",
       "      <th>d_model</th>\n",
       "      <th>d_ff</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>context_length</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer_config</th>\n",
       "      <th>with_backward</th>\n",
       "      <th>test_mean_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.056681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.145867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>False</td>\n",
       "      <td>0.056409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.358861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.035235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.121854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>False</td>\n",
       "      <td>0.033981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.331843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name device  torch_compile  d_model  d_ff  num_layers  \\\n",
       "0  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "1  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "2  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "3  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "4  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "5  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "6  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "7  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "\n",
       "   num_heads  vocab_size  context_length  batch_size optimizer_config  \\\n",
       "0         16       10000             128           1             None   \n",
       "1         16       10000             128           1             None   \n",
       "2         16       10000             128           1    {'lr': 0.001}   \n",
       "3         16       10000             128           1    {'lr': 0.001}   \n",
       "4         16       10000             128           1             None   \n",
       "5         16       10000             128           1             None   \n",
       "6         16       10000             128           1    {'lr': 0.001}   \n",
       "7         16       10000             128           1    {'lr': 0.001}   \n",
       "\n",
       "   with_backward  test_mean_time  \n",
       "0          False        0.056681  \n",
       "1           True        0.145867  \n",
       "2          False        0.056409  \n",
       "3           True        0.358861  \n",
       "4          False        0.035235  \n",
       "5           True        0.121854  \n",
       "6          False        0.033981  \n",
       "7           True        0.331843  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out_llm.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "# df.head()\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"optimizer_config\"], df[\"with_backward\"], df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40f68f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/code/assignment2-systems/profile_results/out_compile_torch.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# for \u001b[39;00m\n\u001b[32m      4\u001b[39m json_file_path = \u001b[33m'\u001b[39m\u001b[33m/home/ubuntu/code/assignment2-systems/profile_results/out_compile_torch.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m json_array = json.load(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      6\u001b[39m df = pd.DataFrame(json_array)\n\u001b[32m      7\u001b[39m pd.concat([pd.json_normalize(df[\u001b[33m\"\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m\"\u001b[39m]), df[\u001b[33m\"\u001b[39m\u001b[33mtest_mean_time\u001b[39m\u001b[33m\"\u001b[39m]], axis = \u001b[32m1\u001b[39m) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my_code/cs336/assignment2-systems/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/ubuntu/code/assignment2-systems/profile_results/out_compile_torch.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# for \n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out_compile_torch.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973b005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a  b    c\n",
       "0  10  1  0.0\n",
       "1  20  2  NaN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 从字典创建 DataFrame\n",
    "data = {\"name\": [\"Alice\", \"Bob\", \"Cathy\"], \"age\": [25, 30, 22]}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel('out.xlsx',  index=False)\n",
    "\n",
    "a = [{'a': 10, 'b': 1, 'c': 0}, {'a': 20, 'b': 2}]\n",
    "df = pd.DataFrame(a)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d85f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([]), tensor(0.1000), tensor(0.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor(0.1, dtype=torch.float32, device = 'cpu')\n",
    "b = torch.zeros_like(a)\n",
    "a.shape, b.shape, a, b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
