{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c4bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.0001)\n",
      "tensor(9.9531, dtype=torch.float16)\n",
      "tensor(10.0021)\n",
      "tensor(10.0021)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def test_mixed_precision():\n",
    "    s = torch.tensor(0, dtype=torch.float32)\n",
    "    for i in range(1000):\n",
    "        s += torch.tensor(0.01, dtype=torch.float32)\n",
    "    print(s)\n",
    "\n",
    "    s = torch.tensor(0, dtype=torch.float16)\n",
    "    for i in range(1000):\n",
    "        s += torch.tensor(0.01, dtype=torch.float16)\n",
    "    print(s)\n",
    "\n",
    "    s = torch.tensor(0, dtype=torch.float32)\n",
    "    for i in range(1000):\n",
    "        s += torch.tensor(0.01, dtype=torch.float16)\n",
    "    print(s)\n",
    "\n",
    "    s = torch.tensor(0, dtype=torch.float32)\n",
    "    for i in range(1000):\n",
    "        x = torch.tensor(0.01, dtype=torch.float16)\n",
    "        s += x.type(torch.float32)\n",
    "    print(s)\n",
    "test_mixed_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33de691a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>device</th>\n",
       "      <th>context_length</th>\n",
       "      <th>d_model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>test_mean_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>1.232675e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>6.029122e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8.740646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3.631009e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1.242491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>5.990281e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>8.887623e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3.752381e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>1.165871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>6.349206e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>9.429654e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4.053141e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>1.197277e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>7.900641e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>1.147472e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>5.041412e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name device  context_length  d_model  batch_size  test_mean_time\n",
       "0   AttentionLayer   cuda             256       16           8    1.232675e-03\n",
       "1   AttentionLayer   cuda            1024       16           8    6.029122e-03\n",
       "2   AttentionLayer   cuda            4096       16           8    8.740646e-02\n",
       "3   AttentionLayer   cuda            8192       16           8    3.631009e-01\n",
       "4   AttentionLayer   cuda           16384       16           8    1.000000e+10\n",
       "5   AttentionLayer   cuda             256       32           8    1.242491e-03\n",
       "6   AttentionLayer   cuda            1024       32           8    5.990281e-03\n",
       "7   AttentionLayer   cuda            4096       32           8    8.887623e-02\n",
       "8   AttentionLayer   cuda            8192       32           8    3.752381e-01\n",
       "9   AttentionLayer   cuda           16384       32           8    1.000000e+10\n",
       "10  AttentionLayer   cuda             256       64           8    1.165871e-03\n",
       "11  AttentionLayer   cuda            1024       64           8    6.349206e-03\n",
       "12  AttentionLayer   cuda            4096       64           8    9.429654e-02\n",
       "13  AttentionLayer   cuda            8192       64           8    4.053141e-01\n",
       "14  AttentionLayer   cuda           16384       64           8    1.000000e+10\n",
       "15  AttentionLayer   cuda             256      128           8    1.197277e-03\n",
       "16  AttentionLayer   cuda            1024      128           8    7.900641e-03\n",
       "17  AttentionLayer   cuda            4096      128           8    1.147472e-01\n",
       "18  AttentionLayer   cuda            8192      128           8    5.041412e-01\n",
       "19  AttentionLayer   cuda           16384      128           8    1.000000e+10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872e23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>device</th>\n",
       "      <th>context_length</th>\n",
       "      <th>d_model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>torch_compile</th>\n",
       "      <th>test_mean_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>8.615449e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.785491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>3.693909e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.726874e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.589174e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.848333e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>4.420176e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.867052e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.494084e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>3.834974e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>4.616002e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.042146e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.699007e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>5.401137e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>6.715345e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.977401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AttentionLayer</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name device  context_length  d_model  batch_size  torch_compile  \\\n",
       "0   AttentionLayer   cuda             256       16           8           True   \n",
       "1   AttentionLayer   cuda            1024       16           8           True   \n",
       "2   AttentionLayer   cuda            4096       16           8           True   \n",
       "3   AttentionLayer   cuda            8192       16           8           True   \n",
       "4   AttentionLayer   cuda           16384       16           8           True   \n",
       "5   AttentionLayer   cuda             256       32           8           True   \n",
       "6   AttentionLayer   cuda            1024       32           8           True   \n",
       "7   AttentionLayer   cuda            4096       32           8           True   \n",
       "8   AttentionLayer   cuda            8192       32           8           True   \n",
       "9   AttentionLayer   cuda           16384       32           8           True   \n",
       "10  AttentionLayer   cuda             256       64           8           True   \n",
       "11  AttentionLayer   cuda            1024       64           8           True   \n",
       "12  AttentionLayer   cuda            4096       64           8           True   \n",
       "13  AttentionLayer   cuda            8192       64           8           True   \n",
       "14  AttentionLayer   cuda           16384       64           8           True   \n",
       "15  AttentionLayer   cuda             256      128           8           True   \n",
       "16  AttentionLayer   cuda            1024      128           8           True   \n",
       "17  AttentionLayer   cuda            4096      128           8           True   \n",
       "18  AttentionLayer   cuda            8192      128           8           True   \n",
       "19  AttentionLayer   cuda           16384      128           8           True   \n",
       "\n",
       "    test_mean_time  \n",
       "0     8.615449e-04  \n",
       "1     2.785491e-03  \n",
       "2     3.693909e-02  \n",
       "3     1.726874e-01  \n",
       "4     1.000000e+10  \n",
       "5     9.589174e-04  \n",
       "6     2.848333e-03  \n",
       "7     4.420176e-02  \n",
       "8     1.867052e-01  \n",
       "9     1.000000e+10  \n",
       "10    9.494084e-04  \n",
       "11    3.834974e-03  \n",
       "12    4.616002e-02  \n",
       "13    2.042146e-01  \n",
       "14    1.000000e+10  \n",
       "15    9.699007e-04  \n",
       "16    5.401137e-03  \n",
       "17    6.715345e-02  \n",
       "18    2.977401e-01  \n",
       "19    1.000000e+10  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out_compile.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcae602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>device</th>\n",
       "      <th>torch_compile</th>\n",
       "      <th>d_model</th>\n",
       "      <th>d_ff</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>context_length</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer_config</th>\n",
       "      <th>with_backward</th>\n",
       "      <th>test_mean_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.056681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.145867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>False</td>\n",
       "      <td>0.056409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.358861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.035235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.121854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>False</td>\n",
       "      <td>0.033981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BasicsTransformerLM</td>\n",
       "      <td>cuda</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>{'lr': 0.001}</td>\n",
       "      <td>True</td>\n",
       "      <td>0.331843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name device  torch_compile  d_model  d_ff  num_layers  \\\n",
       "0  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "1  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "2  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "3  BasicsTransformerLM   cuda          False     1024  4096          24   \n",
       "4  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "5  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "6  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "7  BasicsTransformerLM   cuda           True     1024  4096          24   \n",
       "\n",
       "   num_heads  vocab_size  context_length  batch_size optimizer_config  \\\n",
       "0         16       10000             128           1             None   \n",
       "1         16       10000             128           1             None   \n",
       "2         16       10000             128           1    {'lr': 0.001}   \n",
       "3         16       10000             128           1    {'lr': 0.001}   \n",
       "4         16       10000             128           1             None   \n",
       "5         16       10000             128           1             None   \n",
       "6         16       10000             128           1    {'lr': 0.001}   \n",
       "7         16       10000             128           1    {'lr': 0.001}   \n",
       "\n",
       "   with_backward  test_mean_time  \n",
       "0          False        0.056681  \n",
       "1           True        0.145867  \n",
       "2          False        0.056409  \n",
       "3           True        0.358861  \n",
       "4          False        0.035235  \n",
       "5           True        0.121854  \n",
       "6          False        0.033981  \n",
       "7           True        0.331843  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out_llm.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "# df.head()\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"optimizer_config\"], df[\"with_backward\"], df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40f68f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>device</th>\n",
       "      <th>context_length</th>\n",
       "      <th>d_model</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>torch_compile</th>\n",
       "      <th>test_mean_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>8.252371e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.337567e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.999682e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.417956e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.411155e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.655055e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>3.814833e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.572611e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>9.221252e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>3.257162e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>3.716321e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.705141e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.080458e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>5.096800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>4096</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>6.028807e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>8192</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2.625118e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AttentionLayerTorch</td>\n",
       "      <td>cuda</td>\n",
       "      <td>16384</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name device  context_length  d_model  batch_size  \\\n",
       "0   AttentionLayerTorch   cuda             256       16           8   \n",
       "1   AttentionLayerTorch   cuda            1024       16           8   \n",
       "2   AttentionLayerTorch   cuda            4096       16           8   \n",
       "3   AttentionLayerTorch   cuda            8192       16           8   \n",
       "4   AttentionLayerTorch   cuda           16384       16           8   \n",
       "5   AttentionLayerTorch   cuda             256       32           8   \n",
       "6   AttentionLayerTorch   cuda            1024       32           8   \n",
       "7   AttentionLayerTorch   cuda            4096       32           8   \n",
       "8   AttentionLayerTorch   cuda            8192       32           8   \n",
       "9   AttentionLayerTorch   cuda           16384       32           8   \n",
       "10  AttentionLayerTorch   cuda             256       64           8   \n",
       "11  AttentionLayerTorch   cuda            1024       64           8   \n",
       "12  AttentionLayerTorch   cuda            4096       64           8   \n",
       "13  AttentionLayerTorch   cuda            8192       64           8   \n",
       "14  AttentionLayerTorch   cuda           16384       64           8   \n",
       "15  AttentionLayerTorch   cuda             256      128           8   \n",
       "16  AttentionLayerTorch   cuda            1024      128           8   \n",
       "17  AttentionLayerTorch   cuda            4096      128           8   \n",
       "18  AttentionLayerTorch   cuda            8192      128           8   \n",
       "19  AttentionLayerTorch   cuda           16384      128           8   \n",
       "\n",
       "    torch_compile  test_mean_time  \n",
       "0            True    8.252371e-04  \n",
       "1            True    2.337567e-03  \n",
       "2            True    2.999682e-02  \n",
       "3            True    1.417956e-01  \n",
       "4            True    1.000000e+10  \n",
       "5            True    9.411155e-04  \n",
       "6            True    2.655055e-03  \n",
       "7            True    3.814833e-02  \n",
       "8            True    1.572611e-01  \n",
       "9            True    1.000000e+10  \n",
       "10           True    9.221252e-04  \n",
       "11           True    3.257162e-03  \n",
       "12           True    3.716321e-02  \n",
       "13           True    1.705141e-01  \n",
       "14           True    1.000000e+10  \n",
       "15           True    1.080458e-03  \n",
       "16           True    5.096800e-03  \n",
       "17           True    6.028807e-02  \n",
       "18           True    2.625118e-01  \n",
       "19           True    1.000000e+10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# for \n",
    "json_file_path = '/home/ubuntu/code/assignment2-systems/profile_results/out_compile_torch.json'\n",
    "json_array = json.load(open(json_file_path, 'r'))\n",
    "df = pd.DataFrame(json_array)\n",
    "pd.concat([pd.json_normalize(df[\"model_config\"]), df[\"test_mean_time\"]], axis = 1) # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
